<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MIRS Lab guides - 4&nbsp; Deep Learning pipelines</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./xgboost.html" rel="next">
<link href="./mlpipelines.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./deep_learning.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Deep Learning pipelines</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MIRS Lab guides</a> 
        <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./MIRS-Lab-guides.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./MIRS-Lab-guides.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./howtouse.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">How to use our scripts for mid infrared spectroscopy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Visualization of spectroscopy data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlpipelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Machine learning pipelines</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deep_learning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Deep Learning pipelines</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./xgboost.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">XGboost for spectroscopy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">A closer look into spectral quality</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#a-basic-artificial-neural-network-for-species-classification" id="toc-a-basic-artificial-neural-network-for-species-classification" class="nav-link active" data-scroll-target="#a-basic-artificial-neural-network-for-species-classification"><span class="header-section-number">4.1</span> A basic artificial neural network for species classification</a>
  <ul class="collapse">
  <li><a href="#load-and-preprocess-the-data" id="toc-load-and-preprocess-the-data" class="nav-link" data-scroll-target="#load-and-preprocess-the-data"><span class="header-section-number">4.1.1</span> Load and preprocess the data</a></li>
  <li><a href="#building-the-model" id="toc-building-the-model" class="nav-link" data-scroll-target="#building-the-model"><span class="header-section-number">4.1.2</span> Building the model</a></li>
  <li><a href="#compiling-the-model" id="toc-compiling-the-model" class="nav-link" data-scroll-target="#compiling-the-model"><span class="header-section-number">4.1.3</span> Compiling the model</a></li>
  <li><a href="#training-the-model" id="toc-training-the-model" class="nav-link" data-scroll-target="#training-the-model"><span class="header-section-number">4.1.4</span> Training the model</a></li>
  <li><a href="#evaluate-with-unseen-data" id="toc-evaluate-with-unseen-data" class="nav-link" data-scroll-target="#evaluate-with-unseen-data"><span class="header-section-number">4.1.5</span> Evaluate with unseen data</a></li>
  <li><a href="#save-your-model" id="toc-save-your-model" class="nav-link" data-scroll-target="#save-your-model"><span class="header-section-number">4.1.6</span> Save your model</a></li>
  </ul></li>
  <li><a href="#a-basic-artificial-neural-network-for-multiclass-age-classification" id="toc-a-basic-artificial-neural-network-for-multiclass-age-classification" class="nav-link" data-scroll-target="#a-basic-artificial-neural-network-for-multiclass-age-classification"><span class="header-section-number">4.2</span> A basic artificial neural network for multiclass age classification</a>
  <ul class="collapse">
  <li><a href="#encoding-labels" id="toc-encoding-labels" class="nav-link" data-scroll-target="#encoding-labels"><span class="header-section-number">4.2.1</span> Encoding labels</a></li>
  <li><a href="#building-the-model-1" id="toc-building-the-model-1" class="nav-link" data-scroll-target="#building-the-model-1"><span class="header-section-number">4.2.2</span> Building the model</a></li>
  <li><a href="#evaluate-the-model-with-useen-data" id="toc-evaluate-the-model-with-useen-data" class="nav-link" data-scroll-target="#evaluate-the-model-with-useen-data"><span class="header-section-number">4.2.3</span> Evaluate the model with useen data</a></li>
  <li><a href="#reverse-the-encoding" id="toc-reverse-the-encoding" class="nav-link" data-scroll-target="#reverse-the-encoding"><span class="header-section-number">4.2.4</span> Reverse the encoding</a></li>
  </ul></li>
  <li><a href="#evaluate-your-model-using-crossvalidation." id="toc-evaluate-your-model-using-crossvalidation." class="nav-link" data-scroll-target="#evaluate-your-model-using-crossvalidation."><span class="header-section-number">4.3</span> Evaluate your model using crossvalidation.</a>
  <ul class="collapse">
  <li><a href="#define-the-cross-validator" id="toc-define-the-cross-validator" class="nav-link" data-scroll-target="#define-the-cross-validator"><span class="header-section-number">4.3.1</span> Define the cross-validator</a></li>
  <li><a href="#cross-validation-process" id="toc-cross-validation-process" class="nav-link" data-scroll-target="#cross-validation-process"><span class="header-section-number">4.3.2</span> Cross validation process</a></li>
  <li><a href="#plotting-the-mean-accuracy-and-standard-deviation" id="toc-plotting-the-mean-accuracy-and-standard-deviation" class="nav-link" data-scroll-target="#plotting-the-mean-accuracy-and-standard-deviation"><span class="header-section-number">4.3.3</span> Plotting the mean accuracy and standard deviation</a></li>
  </ul></li>
  <li><a href="#tuning-a-deep-learning-model" id="toc-tuning-a-deep-learning-model" class="nav-link" data-scroll-target="#tuning-a-deep-learning-model"><span class="header-section-number">4.4</span> Tuning a deep learning model</a></li>
  </ul>
<div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="notebooks/deeplearning_primer.ipynb.html"><i class="bi bi-journal-code"></i>deeplearning_primer.ipynb</a></li><li><a href="notebooks/deep_learning_primer_age.ipynb.html"><i class="bi bi-journal-code"></i>deep_learning_primer_age.ipynb</a></li><li><a href="notebooks/deep_learning_cv.ipynb.html"><i class="bi bi-journal-code"></i>deep_learning_cv.ipynb</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Deep Learning pipelines</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Deep learning is a subarea of machine learning that focuses on the use of Artifical Neural Networks (ANN). These type of models have shown to be quite powerfull for infrared spectroscopy. For deep learning analysis, we are going to use TensorFlow. For instructions to install you visit [https://keras.io/]. As always, read the documentation. They have a lot of really well put tutorials to get you started.</p>
<section id="a-basic-artificial-neural-network-for-species-classification" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="a-basic-artificial-neural-network-for-species-classification"><span class="header-section-number">4.1</span> A basic artificial neural network for species classification</h2>
<p>The most basic artifical neural network is the Multilayer Perceptron (MLP). It has following architecture (<a href="#fig-mpl">Figure&nbsp;<span>4.1</span></a>):</p>
<ul>
<li><p>One input layer</p></li>
<li><p>One or more hidden layers</p></li>
<li><p>One final layer called the output layer.</p></li>
</ul>
<div id="fig-mpl" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./figures/MLP_architecture.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4.1: mpl_architecture</figcaption>
</figure>
</div>
<p>Every layer except the output layer includes a bias neuron and is fully connected to the next layer.</p>
<p>We will start with a very simple ANN to predict two species of Anopheles mosquitoes using infrared spectroscopy.</p>
<section id="load-and-preprocess-the-data" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="load-and-preprocess-the-data"><span class="header-section-number">4.1.1</span> Load and preprocess the data</h3>
<p>As mentioned early, we are going to use Tensorflow and Keras to do our deep learning analsysis. Let’s import the packages.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> regularizers</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_docs <span class="im">as</span> tfdocs</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_docs.modeling</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelBinarizer</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Our dataset contains more than 10 categorical targets and around 1812 features.</p>
<div class="quarto-embed-nb-cell">
<div class="cell">
<div id="loaddata" class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Cat1</th>
<th data-quarto-table-cell-role="th">Cat2</th>
<th data-quarto-table-cell-role="th">Cat3</th>
<th data-quarto-table-cell-role="th">Cat4</th>
<th data-quarto-table-cell-role="th">Cat5</th>
<th data-quarto-table-cell-role="th">Cat6</th>
<th data-quarto-table-cell-role="th">Cat7</th>
<th data-quarto-table-cell-role="th">Cat8</th>
<th data-quarto-table-cell-role="th">Cat9</th>
<th data-quarto-table-cell-role="th">Cat10</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">420</th>
<th data-quarto-table-cell-role="th">418</th>
<th data-quarto-table-cell-role="th">416</th>
<th data-quarto-table-cell-role="th">414</th>
<th data-quarto-table-cell-role="th">412</th>
<th data-quarto-table-cell-role="th">410</th>
<th data-quarto-table-cell-role="th">408</th>
<th data-quarto-table-cell-role="th">406</th>
<th data-quarto-table-cell-role="th">404</th>
<th data-quarto-table-cell-role="th">402</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>AC</td>
<td>S</td>
<td>0</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>C1</td>
<td>R1</td>
<td>190823</td>
<td>111223</td>
<td>...</td>
<td>0.2321</td>
<td>0.2309</td>
<td>0.2283</td>
<td>0.2274</td>
<td>0.2275</td>
<td>0.2286</td>
<td>0.2305</td>
<td>0.2316</td>
<td>0.2323</td>
<td>0.2336</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>AC</td>
<td>S</td>
<td>0</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>C1</td>
<td>R1</td>
<td>190823</td>
<td>111223</td>
<td>...</td>
<td>0.2223</td>
<td>0.2198</td>
<td>0.2187</td>
<td>0.2192</td>
<td>0.2195</td>
<td>0.2192</td>
<td>0.2194</td>
<td>0.2211</td>
<td>0.2225</td>
<td>0.2222</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>AC</td>
<td>S</td>
<td>0</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>C1</td>
<td>R1</td>
<td>190823</td>
<td>111223</td>
<td>...</td>
<td>0.2040</td>
<td>0.2028</td>
<td>0.2019</td>
<td>0.2022</td>
<td>0.2037</td>
<td>0.2048</td>
<td>0.2054</td>
<td>0.2056</td>
<td>0.2047</td>
<td>0.2036</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>AC</td>
<td>S</td>
<td>0</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>C1</td>
<td>R1</td>
<td>190823</td>
<td>111223</td>
<td>...</td>
<td>0.2409</td>
<td>0.2389</td>
<td>0.2364</td>
<td>0.2353</td>
<td>0.2360</td>
<td>0.2368</td>
<td>0.2372</td>
<td>0.2380</td>
<td>0.2390</td>
<td>0.2398</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>AC</td>
<td>S</td>
<td>0</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>C1</td>
<td>R1</td>
<td>190823</td>
<td>111223</td>
<td>...</td>
<td>0.2150</td>
<td>0.2155</td>
<td>0.2152</td>
<td>0.2150</td>
<td>0.2154</td>
<td>0.2154</td>
<td>0.2156</td>
<td>0.2165</td>
<td>0.2181</td>
<td>0.2191</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4539</td>
<td>AG</td>
<td>S</td>
<td>31</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>K2</td>
<td>R4</td>
<td>190923</td>
<td>30124</td>
<td>...</td>
<td>0.1638</td>
<td>0.1634</td>
<td>0.1618</td>
<td>0.1608</td>
<td>0.1606</td>
<td>0.1607</td>
<td>0.1617</td>
<td>0.1625</td>
<td>0.1623</td>
<td>0.1616</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4540</td>
<td>AG</td>
<td>S</td>
<td>31</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>K2</td>
<td>R4</td>
<td>190923</td>
<td>30124</td>
<td>...</td>
<td>0.2457</td>
<td>0.2438</td>
<td>0.2424</td>
<td>0.2420</td>
<td>0.2425</td>
<td>0.2440</td>
<td>0.2457</td>
<td>0.2465</td>
<td>0.2461</td>
<td>0.2443</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4541</td>
<td>AG</td>
<td>S</td>
<td>31</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>K2</td>
<td>R4</td>
<td>190923</td>
<td>30124</td>
<td>...</td>
<td>0.2676</td>
<td>0.2667</td>
<td>0.2678</td>
<td>0.2682</td>
<td>0.2674</td>
<td>0.2683</td>
<td>0.2712</td>
<td>0.2717</td>
<td>0.2695</td>
<td>0.2685</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4542</td>
<td>AG</td>
<td>S</td>
<td>31</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>K2</td>
<td>R4</td>
<td>190923</td>
<td>30124</td>
<td>...</td>
<td>0.2725</td>
<td>0.2718</td>
<td>0.2681</td>
<td>0.2659</td>
<td>0.2661</td>
<td>0.2681</td>
<td>0.2708</td>
<td>0.2727</td>
<td>0.2736</td>
<td>0.2741</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4543</td>
<td>AG</td>
<td>S</td>
<td>31</td>
<td>YY</td>
<td>SU</td>
<td>T1</td>
<td>K2</td>
<td>R4</td>
<td>190923</td>
<td>30124</td>
<td>...</td>
<td>0.2230</td>
<td>0.2238</td>
<td>0.2225</td>
<td>0.2199</td>
<td>0.2185</td>
<td>0.2193</td>
<td>0.2213</td>
<td>0.2231</td>
<td>0.2230</td>
<td>0.2223</td>
</tr>
</tbody>
</table>

<p>4544 rows × 1812 columns</p>
</div>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-1" href="notebooks/deeplearning_primer.ipynb.html">Source: deeplearning_primer.ipynb</a></div>
<p>We checked that our classes are balanced, which in this example they are not.</p>
<div class="quarto-embed-nb-cell">
<div id="classes" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df.groupby([<span class="st">'Cat1'</span>])[<span class="st">'Cat2'</span>].count().plot.bar()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="classes-1" class="cell-output cell-output-display" data-execution_count="3">
<pre><code>&lt;Axes: xlabel='Cat1'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="deep_learning_files/figure-html/classes-output-2.png" id="classes-2" class="img-fluid"></p>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-2" href="notebooks/deeplearning_primer.ipynb.html#classes">Source: deeplearning_primer.ipynb</a></div>
<p>After we divide our data set into wavenumbers (X) and labels(y), we can use the <code>imblearn</code> package which allows to resample the class to match the underespresent class.</p>
<div class="quarto-embed-nb-cell">
<div id="resampling" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.under_sampling <span class="im">import</span> RandomUnderSampler</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>rus <span class="op">=</span> RandomUnderSampler(random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>X_resampled, y_resampled <span class="op">=</span> rus.fit_resample(X, y)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">sorted</span>(Counter(y_resampled).items()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[('AC', 1724), ('AG', 1724)]</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-3" href="notebooks/deeplearning_primer.ipynb.html#resampling">Source: deeplearning_primer.ipynb</a></div>
<p>Also, we need to encode our labels (transform species names into 1 or 0) using <code>LabelBinarizer</code>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change the labels into 0 or 1</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>lb <span class="op">=</span> LabelBinarizer()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y_binary <span class="op">=</span> lb.fit_transform(y_resampled)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We split our data set into train and test sets. We are going to use our test set for the final evaluation of our ANN model. It is good practice to scale the data, for this we are using standard scaling.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into train and test </span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_resampled, y_binary, stratify<span class="op">=</span>y_binary, shuffle<span class="op">=</span><span class="va">True</span>, test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Scaling train and test</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>When applying scaling, be sure you fit_transform the train test and only transform the test set. Moreover, scale the data after split it to avoid data leakege.</p>
</div>
</div>
<p>We further split the training set into training and validation.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split it further train set into train and validation</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>X_train_2, X_val, y_train_2, y_val <span class="op">=</span> train_test_split(X_train, y_train, stratify<span class="op">=</span>y_train, shuffle<span class="op">=</span><span class="va">True</span>, test_size<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>One of the things that you can do with keras is the use of callbacks. A callback is an object that can perform actions at various stages of training (e.g.&nbsp;at the start or end of an epoch, before or after a single batch, etc).</p>
<p>You can use callbacks to: Periodically save your model to disk Do early stopping, Get a view on internal states and statistics of a model during training, etc. Here, we are using it to avoid too much print messages during training.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># functions to eliminate part of the messages when training ANN</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_callbacks(name):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    tfdocs.modeling.EpochDots()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="building-the-model" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="building-the-model"><span class="header-section-number">4.1.2</span> Building the model</h3>
<p>We create our the model using the Sequential API as follows:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define the keras model</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>input_shape <span class="op">=</span> [<span class="dv">1796</span>,]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> keras.Sequential()</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>model.add(keras.layers.Input(shape<span class="op">=</span>input_shape))</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>model.add(keras.layers.Dense(<span class="dv">500</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>model.add(keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s go line by line: 1. The first line define the input of the model, which matches how many features (wavenumbers) we have in our data set. 2. <code>Keras.sequential</code> will create an object called ‘model’ in which we can add layers. 3. We add our first layer, the input layer. It has the shape of our previously define input 4. A first hidden layer, with 500 neurons and <code>'relu'</code> activation 5. the final output layer with 1 neuron (becuase we are tackling a binary classification) with a <code>sigmoid</code> activation</p>
</section>
<section id="compiling-the-model" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="compiling-the-model"><span class="header-section-number">4.1.3</span> Compiling the model</h3>
<p>Once the model is created, we compile it. Here, we defined the loss function (binary crossentropy), the optimizer (adam) and the metric (accuracy) to assess how well our model classifiy our data set.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>we can check the model using summary</p>
<div class="quarto-embed-nb-cell">
<div id="summary" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="summary-1" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential"</span>
</pre>
</div>
<div id="summary-2" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ dense (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>)            │       <span style="color: #00af00; text-decoration-color: #00af00">898,500</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              │           <span style="color: #00af00; text-decoration-color: #00af00">501</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div>
<div id="summary-3" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">899,001</span> (3.43 MB)
</pre>
</div>
<div id="summary-4" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">899,001</span> (3.43 MB)
</pre>
</div>
<div id="summary-5" class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-4" href="notebooks/deeplearning_primer.ipynb.html#summary">Source: deeplearning_primer.ipynb</a></div>
<p>In the following table, you can see what parameters you can start on when building your models depeding on the classification problem.</p>
<table class="table">
<caption>Typical classification MLP architecture</caption>
<colgroup>
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 17%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Hyperparameter</th>
<th>Regression</th>
<th>Binary classification</th>
<th>Multilabel classification</th>
<th>Multiclass classification</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td># input neurons</td>
<td>One per input feature</td>
<td>One per input feature</td>
<td>One per input feature</td>
<td>One per input feature</td>
</tr>
<tr class="even">
<td># hidden layers</td>
<td>1 - 5</td>
<td>1 - 5</td>
<td>1 - 5</td>
<td>1 - 5</td>
</tr>
<tr class="odd">
<td># neurons per hidden layer</td>
<td>10 - 100</td>
<td>10 - 100</td>
<td>10 - 100</td>
<td>10 - 100</td>
</tr>
<tr class="even">
<td># output neurons</td>
<td>1 per prediction dimension</td>
<td>1</td>
<td>1 per label</td>
<td>1 per class</td>
</tr>
<tr class="odd">
<td>Hidden activation</td>
<td>reLU</td>
<td>reLU</td>
<td>reLU</td>
<td>reLU</td>
</tr>
<tr class="even">
<td>Output activation</td>
<td>None</td>
<td>Logistic</td>
<td>Logistic</td>
<td>Softmax</td>
</tr>
<tr class="odd">
<td>Loss function</td>
<td>MSE</td>
<td>Cross entropy</td>
<td>Cross entropy</td>
<td>Cross entropy</td>
</tr>
</tbody>
</table>
</section>
<section id="training-the-model" class="level3" data-number="4.1.4">
<h3 data-number="4.1.4" class="anchored" data-anchor-id="training-the-model"><span class="header-section-number">4.1.4</span> Training the model</h3>
<p>We train the model with <code>fit()</code> function. Here, you specify you x and y, number of epochs, batch size and validation data. Also, you can add callbacks</p>
<div class="quarto-embed-nb-cell">
<div id="fit" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(x<span class="op">=</span>X_train_2, y<span class="op">=</span>y_train_2, epochs<span class="op">=</span><span class="dv">500</span>, batch_size<span class="op">=</span><span class="dv">250</span>, validation_data<span class="op">=</span>[X_val, y_val],verbose<span class="op">=</span><span class="dv">0</span>,callbacks<span class="op">=</span>get_callbacks(<span class="st">'model_baseline'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Epoch: 0, accuracy:0.6011,  loss:1.5072,  val_accuracy:0.6159,  val_loss:0.9330,  
....................................................................................................
Epoch: 100, accuracy:0.9402,  loss:0.1599,  val_accuracy:0.8424,  val_loss:0.4303,  
....................................................................................................
Epoch: 200, accuracy:0.9465,  loss:0.1408,  val_accuracy:0.8351,  val_loss:0.5025,  
....................................................................................................
Epoch: 300, accuracy:0.9986,  loss:0.0207,  val_accuracy:0.8696,  val_loss:0.5299,  
....................................................................................................
Epoch: 400, accuracy:0.9995,  loss:0.0109,  val_accuracy:0.8750,  val_loss:0.5526,  
....................................................................................................</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-5" href="notebooks/deeplearning_primer.ipynb.html#fit">Source: deeplearning_primer.ipynb</a></div>
<p>We saved all the information of accuracy, loss when using the training set and validation set for each epoch in the <code>history</code> variable. You can access the information by using the <code>history</code> attribute. A good way to see if your model is overfitting or underfitting is by plotting the values of training/validation loss and accuracy.</p>
<div class="quarto-embed-nb-cell">
<div id="validationcurves" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check training and validation curves</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>fig, (ax, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">5</span>), tight_layout<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>ax.plot(epochs, loss, <span class="st">'r-'</span>, label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>ax.plot(epochs, val_loss, <span class="st">'b--'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Training and validation loss'</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Epochs'</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> history.history[<span class="st">'accuracy'</span>]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>val_acc <span class="op">=</span> history.history[<span class="st">'val_accuracy'</span>]</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, acc, <span class="st">'r-'</span>, label<span class="op">=</span><span class="st">'Training acc'</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, val_acc, <span class="st">'b--'</span>, label<span class="op">=</span><span class="st">'Validation acc'</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Training and validation accuracy'</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Epochs'</span>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>ax2.set_ylim(<span class="dv">0</span>,<span class="fl">1.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="validationcurves-1" class="cell-output cell-output-display" data-execution_count="28">
<pre><code>(0.0, 1.5)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="deep_learning_files/figure-html/validationcurves-output-2.png" id="validationcurves-2" class="img-fluid"></p>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-6" href="notebooks/deeplearning_primer.ipynb.html#validationcurves">Source: deeplearning_primer.ipynb</a></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Start we few epochs to see how your computer handles the training. Currently, all these examples are tested on a Macbook pro M1 max pro with 32 GB of ram.</p>
</div>
</div>
<p>We are not going to discuss overfitting or undefitting in this section yet.</p>
</section>
<section id="evaluate-with-unseen-data" class="level3" data-number="4.1.5">
<h3 data-number="4.1.5" class="anchored" data-anchor-id="evaluate-with-unseen-data"><span class="header-section-number">4.1.5</span> Evaluate with unseen data</h3>
<p>We got a pretty decent accuracy with a simple MPL model. Now, we evaluate on the test set</p>
<div class="quarto-embed-nb-cell">
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># model evaluation</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>model.evaluate(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>22/22 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8840 - loss: 0.4466</code></pre>
</div>
<div id="evaluation" class="cell-output cell-output-display" data-execution_count="17">
<pre><code>[0.4332384169101715, 0.8927536010742188]</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-7" href="notebooks/deeplearning_primer.ipynb.html">Source: deeplearning_primer.ipynb</a></div>
<p>We got an accuracy of 0.89 which is pretty good.</p>
<p>As always, it is good to have confusion matrices to have a better understanding of the model perfomance. Therefore, we make predictions using X_test.</p>
<div class="quarto-embed-nb-cell">
<div id="predictions" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>y_proba <span class="op">=</span> model.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>22/22 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step </code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-8" href="notebooks/deeplearning_primer.ipynb.html#predictions">Source: deeplearning_primer.ipynb</a></div>
<p>We round this predictions since they are probailities</p>
<div class="quarto-embed-nb-cell">
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions will be a probability in the range between 0 and 1. So, we round them to have binary predictions</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>y_predicted <span class="op">=</span> y_proba.<span class="bu">round</span>(<span class="dv">0</span>).astype(<span class="bu">int</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>y_predicted[<span class="dv">0</span>:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="predictions2" class="cell-output cell-output-display" data-execution_count="19">
<pre><code>array([[1],
       [1],
       [1],
       [1],
       [0]])</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-9" href="notebooks/deeplearning_primer.ipynb.html">Source: deeplearning_primer.ipynb</a></div>
<p>and then we compute and plot the final confusion matrix</p>
<div class="quarto-embed-nb-cell">
<div id="finalcm" class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(y_pred<span class="op">=</span>lb.inverse_transform(y_predicted), y_true<span class="op">=</span>lb.inverse_transform(y_test), normalize<span class="op">=</span><span class="st">'true'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>,im_kw<span class="op">=</span>{<span class="st">'vmin'</span>:<span class="dv">0</span>, <span class="st">'vmax'</span>:<span class="dv">1</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="finalcm-1" class="cell-output cell-output-display" data-execution_count="20">
<pre><code>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x157215fa0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="deep_learning_files/figure-html/finalcm-output-2.png" id="finalcm-2" class="img-fluid"></p>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-10" href="notebooks/deeplearning_primer.ipynb.html#finalcm">Source: deeplearning_primer.ipynb</a></div>
<p>Both classes have quite high accuracy. So we are happy.</p>
</section>
<section id="save-your-model" class="level3" data-number="4.1.6">
<h3 data-number="4.1.6" class="anchored" data-anchor-id="save-your-model"><span class="header-section-number">4.1.6</span> Save your model</h3>
<p>Training ANN can be quite long and computational expensive. Therefore, it is good practice to save it.</p>
<div class="quarto-embed-nb-cell">
<div id="savemodel" class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># save your model</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>model.save(<span class="st">"./models/my_first_keras_model.keras"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-11" href="notebooks/deeplearning_primer.ipynb.html#savemodel">Source: deeplearning_primer.ipynb</a></div>
<p>You can load your trained model again if you want to continue the project.</p>
<div class="quarto-embed-nb-cell">
<div id="loadmodel" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load your model</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>model_new <span class="op">=</span> keras.models.load_model(<span class="st">"./models/my_first_keras_model.keras"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-12" href="notebooks/deeplearning_primer.ipynb.html#loadmodel">Source: deeplearning_primer.ipynb</a></div>
</section>
</section>
<section id="a-basic-artificial-neural-network-for-multiclass-age-classification" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="a-basic-artificial-neural-network-for-multiclass-age-classification"><span class="header-section-number">4.2</span> A basic artificial neural network for multiclass age classification</h2>
<p>The main workflow is exactly the same as for a binary classification. We only need to do some preprocessing to the age classes so they can be read and used bt the neural network.</p>
<p>For this example, we subset the original data set using only An. gambiae data. We converted our ages that were numerical into three different categories.</p>
<div class="quarto-embed-nb-cell">
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>df_gambiae[<span class="st">'Age groups'</span>].unique()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="agegroups" class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array(['0 - 6d', '8 - 16d', '18 - 31d'], dtype=object)</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-13" href="notebooks/deep_learning_primer_age.ipynb.html">Source: deep_learning_primer_age.ipynb</a></div>
<p>The new age grups are not as imbalanced so we will pass. Otherwise, you need to balance the groups</p>
<div class="quarto-embed-nb-cell">
<div id="balanced" class="cell">
<div id="balanced-1" class="cell-output cell-output-display" data-execution_count="10">
<pre><code>&lt;Axes: xlabel='Age groups'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="deep_learning_files/figure-html/balanced-output-2.png" id="balanced-2" class="img-fluid"></p>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-14" href="notebooks/deep_learning_primer_age.ipynb.html#balanced">Source: deep_learning_primer_age.ipynb</a></div>
<section id="encoding-labels" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="encoding-labels"><span class="header-section-number">4.2.1</span> Encoding labels</h3>
<p>This is where things get a little more complicated. Keras models do not support labels as it is (you cannot pass the y as categories). Therefore, to make it work we need to encode our labels in a specific way.</p>
<p>First, encode our target labels with values between 0 and n_classes-1. For this, we use <code>LabelEncoder</code></p>
<div class="quarto-embed-nb-cell">
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode the labels from 0 to n-1 classes</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>encoded_y <span class="op">=</span> encoder.fit_transform(y)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>encoder.classes_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="encode" class="cell-output cell-output-display" data-execution_count="27">
<pre><code>array(['0 - 6d', '18 - 31d', '8 - 16d'], dtype=object)</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-15" href="notebooks/deep_learning_primer_age.ipynb.html">Source: deep_learning_primer_age.ipynb</a></div>
<p>Each age group is an integer, <code>'0 - 6d'</code> is 0, <code>'18 - 31d'</code> is 1 and <code>'8 - 16d'</code> is 2.</p>
<p>We need to transform the encoded labels into a binary matrix. This is called OneHotEncoding</p>
<div class="quarto-embed-nb-cell">
<div id="hotencoding" class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># transform the encoded labels into a binary class matrix</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>yhot <span class="op">=</span> utils.to_categorical(encoded_y)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(yhot)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(yhot.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1. 0. 0.]
 [1. 0. 0.]
 [1. 0. 0.]
 ...
 [0. 1. 0.]
 [0. 1. 0.]
 [0. 1. 0.]]
(2820, 3)</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-16" href="notebooks/deep_learning_primer_age.ipynb.html#hotencoding">Source: deep_learning_primer_age.ipynb</a></div>
<p>As you can see, each age group has 3 values. For the first sample, the values <code>[1. 0. 0.]</code> means that the sample belongs to the group 0 or 0 - 6d. The last sample <code>[0. 1. 0.]</code> belongs to the group 1 or 18 - 31d.</p>
</section>
<section id="building-the-model-1" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="building-the-model-1"><span class="header-section-number">4.2.2</span> Building the model</h3>
<p>For this model we need to change the neurons of the last layer to match the number of labels we have, in this case is 3 and change the activation function to <code>softmax</code>. Moreover, we need to use <code>categorical_crossentropy</code> as loss function. And that’s all</p>
<div class="quarto-embed-nb-cell">
<div id="modelage" class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>input_shape <span class="op">=</span> [<span class="dv">1800</span>,]</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> keras.Sequential()</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>model.add(keras.layers.Input(shape<span class="op">=</span>input_shape))</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>model.add(keras.layers.Dense(<span class="dv">500</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>model.add(keras.layers.Dense(<span class="dv">3</span>, activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># compile the keras model</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-17" href="notebooks/deep_learning_primer_age.ipynb.html#modelage">Source: deep_learning_primer_age.ipynb</a></div>
<p>After training the model we can see that we got pretty high accuracies.</p>
<div class="quarto-embed-nb-cell">
<div id="lossmulti" class="cell">
<div id="lossmulti-1" class="cell-output cell-output-display" data-execution_count="41">
<pre><code>(0.0, 1.5)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="deep_learning_files/figure-html/lossmulti-output-2.png" id="lossmulti-2" class="img-fluid"></p>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-18" href="notebooks/deep_learning_primer_age.ipynb.html#lossmulti">Source: deep_learning_primer_age.ipynb</a></div>
</section>
<section id="evaluate-the-model-with-useen-data" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="evaluate-the-model-with-useen-data"><span class="header-section-number">4.2.3</span> Evaluate the model with useen data</h3>
<p>We evaluate the model using unseen data and we got and accuracy of 82%.</p>
<div class="quarto-embed-nb-cell">
<div id="eval" class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>18/18 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8238 - loss: 0.6882
18/18 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step </code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-19" href="notebooks/deep_learning_primer_age.ipynb.html#eval">Source: deep_learning_primer_age.ipynb</a></div>
</section>
<section id="reverse-the-encoding" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="reverse-the-encoding"><span class="header-section-number">4.2.4</span> Reverse the encoding</h3>
<p>We need to compute the confusion matrix and for that we need to reverse the encoding of our predicted vector and our test vector.</p>
<p>ANN will give us the probability of the sample to belong to each of the 3 categories.</p>
<div class="quarto-embed-nb-cell">
<div id="probasample" class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the model gave us the proability of that samples to be 0, 1 or 2 category</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_proba[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1.9061598e-07 6.7195423e-02 9.3280441e-01]</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-20" href="notebooks/deep_learning_primer_age.ipynb.html#probasample">Source: deep_learning_primer_age.ipynb</a></div>
<p>Here, we can see that this sample belongs to the category 2 or 8 - 16 d</p>
<p>To change to a vector of 1 dimension with the values of each category before we applied one hot encoding, we use the functon <code>np.argmax</code> which will go through each row and give us the index of the highest value.</p>
<div class="quarto-embed-nb-cell">
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the index with the highest value</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.argmax(y_proba, axis<span class="op">=</span><span class="dv">1</span>) </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="argmax" class="cell-output cell-output-display" data-execution_count="44">
<pre><code>array([2, 2, 1, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0,
       2, 2, 0, 1, 0, 0, 2, 0, 1, 1, 0, 2, 2, 0, 0, 0, 2, 0, 1, 2, 2, 2,
       2, 1, 1, 0, 2, 2, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0,
       2, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 1, 0, 2, 0, 2, 2, 2, 2, 1, 0, 2,
       2, 1, 1, 2, 0, 2, 0, 1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 0, 2,
       1, 1, 1, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 2, 1, 1, 0, 2, 1,
       0, 1, 2, 1, 2, 0, 0, 0, 2, 2, 1, 0, 1, 2, 2, 0, 2, 2, 0, 1, 1, 1,
       2, 0, 2, 1, 0, 0, 0, 2, 2, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2,
       2, 1, 1, 0, 1, 1, 0, 2, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 1, 0, 2,
       2, 0, 0, 0, 2, 2, 1, 1, 0, 0, 1, 1, 2, 0, 1, 2, 0, 0, 2, 2, 2, 0,
       0, 1, 1, 1, 0, 1, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 1, 2, 0, 2, 0,
       0, 2, 2, 0, 0, 0, 0, 2, 2, 1, 0, 2, 1, 2, 0, 2, 1, 0, 1, 0, 1, 1,
       2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 2, 1, 1, 1, 0,
       2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 1, 2, 0, 2, 2, 1, 0, 0,
       1, 1, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,
       1, 2, 1, 2, 1, 2, 0, 0, 2, 2, 2, 2, 0, 2, 1, 1, 1, 1, 2, 2, 0, 0,
       2, 2, 0, 0, 0, 2, 0, 1, 0, 2, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 2, 2,
       2, 0, 2, 2, 0, 1, 1, 2, 1, 0, 2, 2, 0, 2, 0, 1, 1, 1, 1, 0, 2, 1,
       0, 0, 1, 2, 0, 2, 0, 1, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0,
       1, 2, 0, 0, 0, 2, 2, 1, 1, 2, 2, 1, 0, 2, 2, 0, 1, 0, 1, 0, 1, 2,
       2, 1, 0, 0, 1, 2, 0, 2, 0, 2, 1, 1, 2, 0, 0, 1, 1, 0, 2, 1, 1, 2,
       1, 0, 1, 1, 0, 1, 2, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 2, 1, 1, 2,
       2, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 2, 2, 1, 0, 2, 2, 2,
       1, 2, 0, 1, 0, 1, 1, 2, 0, 1, 0, 2, 1, 2, 1, 0, 0, 2, 1, 0, 2, 0,
       1, 0, 0, 0, 2, 2, 1, 1, 2, 2, 1, 0, 2, 0, 0, 2, 0, 1, 2, 2, 2, 2,
       0, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0])</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-21" href="notebooks/deep_learning_primer_age.ipynb.html">Source: deep_learning_primer_age.ipynb</a></div>
<p>You can see that you have a vector with the encoded categories from 0 to 2. We need to pass these indexes to the encoder. There are two ways of doing this, using <code>encoder.classes_</code> attribute or the <code>inverse_transform</code> function.</p>
<div class="quarto-embed-nb-cell">
<div id="reverse" class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reverse the encoding to obtaing the original classes</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co"># one way of doing is using the argument classes from the encoder and pass the indexes of the highest values of the probabilities for each class. </span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>y_pred_oneform <span class="op">=</span> encoder.classes_[np.argmax(y_proba,axis<span class="op">=</span><span class="dv">1</span>)]</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># the second way is use the inverse transform function from the encoder to get the original classes</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>y_pred_secform <span class="op">=</span> encoder.inverse_transform(y_pred) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-22" href="notebooks/deep_learning_primer_age.ipynb.html#reverse">Source: deep_learning_primer_age.ipynb</a></div>
<p>Both approaches give the same results</p>
<div class="quarto-embed-nb-cell">
<div id="same" class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># they are the same</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_pred_oneform[<span class="dv">0</span>])</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_pred_secform[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>8 - 16d
8 - 16d</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-23" href="notebooks/deep_learning_primer_age.ipynb.html#same">Source: deep_learning_primer_age.ipynb</a></div>
<p>We apply the same process to the y_test and we compute our confusion matrix</p>
<div class="quarto-embed-nb-cell">
<div id="cm" class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_predictions(</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    y_pred<span class="op">=</span>encoder.inverse_transform(y_pred),</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    y_true<span class="op">=</span>encoder.inverse_transform(y_new_test),</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    normalize<span class="op">=</span><span class="st">'true'</span>,</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    im_kw<span class="op">=</span>{<span class="st">'vmin'</span>:<span class="dv">0</span>, <span class="st">'vmax'</span>:<span class="dv">1</span>},</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[<span class="st">'0 - 6d'</span>, <span class="st">'8 - 16d'</span>, <span class="st">'18 - 31d'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="cm-1" class="cell-output cell-output-display" data-execution_count="51">
<pre><code>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1047cdfd0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="deep_learning_files/figure-html/cm-output-2.png" id="cm-2" class="img-fluid"></p>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-24" href="notebooks/deep_learning_primer_age.ipynb.html#cm">Source: deep_learning_primer_age.ipynb</a></div>
<p>We pass a list of the age groops in the labels parameter to show the correct order of the labels. Otherwise, it the 8 - 16d group will appear last.</p>
<p>if you want to learn more activations check this nice <a href="https://towardsdatascience.com/everything-you-need-to-know-about-activation-functions-in-deep-learning-models-84ba9f82c253">article</a></p>
<p>The simplest way to prevent overfitting is to start with a small model: A model with a small number of learnable parameters (which is determined by the number of layers and the number of units per layer). In deep learning, the number of learnable parameters in a model is often referred to as the model’s “capacity”.</p>
<p>Intuitively, a model with more parameters will have more “memorization capacity” and therefore will be able to easily learn a perfect dictionary-like mapping between training samples and their targets, a mapping without any generalization power, but this would be useless when making predictions on previously unseen data.</p>
<p>Always keep this in mind: deep learning models tend to be good at fitting to the training data, but the real challenge is generalization, not fitting.</p>
<p>On the other hand, if the network has limited memorization resources, it will not be able to learn the mapping as easily. To minimize its loss, it will have to learn compressed representations that have more predictive power. At the same time, if you make your model too small, it will have difficulty fitting to the training data. There is a balance between “too much capacity” and “not enough capacity”.</p>
<p>Unfortunately, there is no magical formula to determine the right size or architecture of your model (in terms of the number of layers, or the right size for each layer). You will have to experiment using a series of different architectures.</p>
<p>To find an appropriate model size, it’s best to start with relatively few layers and parameters, then begin increasing the size of the layers or adding new layers until you see diminishing returns on the validation loss.</p>
<p>Start with a simple model using only densely-connected layers (tf.keras.layers.Dense) as a baseline, then create larger models, and compare them.</p>
</section>
</section>
<section id="evaluate-your-model-using-crossvalidation." class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="evaluate-your-model-using-crossvalidation."><span class="header-section-number">4.3</span> Evaluate your model using crossvalidation.</h2>
<p>So far, all the evaluation has been done in a single split of the data sets.Your results will depend on how your data set is split everytime (unless you set a seed). We might want to see how stable is the model with different parts of the data set.</p>
<p>The approach is very similar to ML pipelines section. for this example, we are going to use the whole data set.</p>
<section id="define-the-cross-validator" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="define-the-cross-validator"><span class="header-section-number">4.3.1</span> Define the cross-validator</h3>
<p>First, we need to define our cross-validator. Here, we used <code>Stratifiedkfold</code>. The difference between this and Kfold is that Stratifeldkfold maitains the percetage of each class on each fold.</p>
<div class="quarto-embed-nb-cell">
<div id="crossvalidator" class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>sss <span class="op">=</span> StratifiedKFold(n_splits<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>                      shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>                      random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># define the callbacks</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_callbacks(name):</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>    tfdocs.modeling.EpochDots()</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>  ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<a class="quarto-notebook-link" id="nblink-25" href="notebooks/deep_learning_cv.ipynb.html#crossvalidator">Source: deep_learning_cv.ipynb</a></div>
</section>
<section id="cross-validation-process" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="cross-validation-process"><span class="header-section-number">4.3.2</span> Cross validation process</h3>
<p>Now, the big loop. We create a dictionary called <code>histories</code> where we are going to save the results of each fold. We got the first split, and we print the fold number. Clear any model that we have made prviously to save memory (other wise you will get covered of all the models you create on each loop). We build our model, and compile it.</p>
<p>We create a new key in the dictionary <code>histories</code> that has the number of the fold and all the results of the fit. This process will happen 5 times. Each time, our model will be trained using for 2000 epochs. This process took 20 minutes in a high end computer so be careful before run the example. It is better if you start with few folds and the epochs beforehand.</p>
<div class="quarto-embed-nb-cell">
<div id="bigloop" class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>histories <span class="op">=</span> {}</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (train_index, test_index) <span class="kw">in</span> <span class="bu">enumerate</span>(sss.split(X_resampled, y_binary)):</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Fold </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    keras.backend.clear_session()</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    input_shape <span class="op">=</span> [<span class="dv">1796</span>,]</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> keras.Sequential()</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    model.add(keras.layers.Input(shape<span class="op">=</span>input_shape))</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    model.add(keras.layers.Dense(<span class="dv">500</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    model.add(keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>    histories[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>] <span class="op">=</span> model.fit(x<span class="op">=</span>X_resampled[train_index], y<span class="op">=</span>y_binary[train_index], epochs<span class="op">=</span><span class="dv">2000</span>, batch_size<span class="op">=</span><span class="dv">250</span>, validation_data<span class="op">=</span>[X_resampled[test_index], y_binary[test_index]],verbose<span class="op">=</span><span class="dv">0</span>,callbacks<span class="op">=</span>get_callbacks(<span class="st">'model_baseline'</span>))</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Fold 0:

Epoch: 0, accuracy:0.5004,  loss:0.7859,  val_accuracy:0.5000,  val_loss:0.7151,  
....................................................................................................
Epoch: 100, accuracy:0.6302,  loss:0.6369,  val_accuracy:0.6261,  val_loss:0.6385,  
....................................................................................................
Epoch: 200, accuracy:0.6925,  loss:0.5858,  val_accuracy:0.6826,  val_loss:0.5977,  
....................................................................................................
Epoch: 300, accuracy:0.6958,  loss:0.5760,  val_accuracy:0.6290,  val_loss:0.6426,  
....................................................................................................
Epoch: 400, accuracy:0.7288,  loss:0.5394,  val_accuracy:0.7000,  val_loss:0.5660,  
....................................................................................................
Epoch: 500, accuracy:0.7194,  loss:0.5430,  val_accuracy:0.6870,  val_loss:0.5789,  
....................................................................................................
Epoch: 600, accuracy:0.7360,  loss:0.5223,  val_accuracy:0.6870,  val_loss:0.5534,  
....................................................................................................
Epoch: 700, accuracy:0.7509,  loss:0.5021,  val_accuracy:0.7101,  val_loss:0.5307,  
....................................................................................................
Epoch: 800, accuracy:0.7426,  loss:0.5058,  val_accuracy:0.7333,  val_loss:0.5299,  
....................................................................................................
Epoch: 900, accuracy:0.7571,  loss:0.4992,  val_accuracy:0.6841,  val_loss:0.5768,  
....................................................................................................
Epoch: 1000, accuracy:0.7596,  loss:0.4885,  val_accuracy:0.7145,  val_loss:0.5191,  
....................................................................................................
Epoch: 1100, accuracy:0.7774,  loss:0.4740,  val_accuracy:0.7435,  val_loss:0.5232,  
....................................................................................................
Epoch: 1200, accuracy:0.7574,  loss:0.4801,  val_accuracy:0.7319,  val_loss:0.5226,  
....................................................................................................
Epoch: 1300, accuracy:0.7455,  loss:0.5106,  val_accuracy:0.7464,  val_loss:0.4971,  
....................................................................................................
Epoch: 1400, accuracy:0.7868,  loss:0.4572,  val_accuracy:0.7623,  val_loss:0.4917,  
....................................................................................................
Epoch: 1500, accuracy:0.7621,  loss:0.4860,  val_accuracy:0.7536,  val_loss:0.4856,  
....................................................................................................
Epoch: 1600, accuracy:0.7737,  loss:0.4624,  val_accuracy:0.7420,  val_loss:0.4850,  
....................................................................................................
Epoch: 1700, accuracy:0.7857,  loss:0.4510,  val_accuracy:0.7246,  val_loss:0.5049,  
....................................................................................................
Epoch: 1800, accuracy:0.7817,  loss:0.4492,  val_accuracy:0.7696,  val_loss:0.4647,  
....................................................................................................
Epoch: 1900, accuracy:0.7524,  loss:0.5048,  val_accuracy:0.7464,  val_loss:0.4772,  
....................................................................................................
Fold 1:

Epoch: 0, accuracy:0.4819,  loss:0.7814,  val_accuracy:0.5000,  val_loss:0.7579,  
....................................................................................................
Epoch: 100, accuracy:0.6599,  loss:0.6188,  val_accuracy:0.6609,  val_loss:0.6150,  
....................................................................................................
Epoch: 200, accuracy:0.6860,  loss:0.5942,  val_accuracy:0.6957,  val_loss:0.5802,  
....................................................................................................
Epoch: 300, accuracy:0.6900,  loss:0.5743,  val_accuracy:0.6609,  val_loss:0.6006,  
....................................................................................................
Epoch: 400, accuracy:0.7016,  loss:0.5613,  val_accuracy:0.7174,  val_loss:0.5520,  
....................................................................................................
Epoch: 500, accuracy:0.7226,  loss:0.5387,  val_accuracy:0.7391,  val_loss:0.5370,  
....................................................................................................
Epoch: 600, accuracy:0.7281,  loss:0.5275,  val_accuracy:0.7275,  val_loss:0.5403,  
....................................................................................................
Epoch: 700, accuracy:0.7408,  loss:0.5179,  val_accuracy:0.7449,  val_loss:0.5244,  
....................................................................................................
Epoch: 800, accuracy:0.7404,  loss:0.5070,  val_accuracy:0.7522,  val_loss:0.5268,  
....................................................................................................
Epoch: 900, accuracy:0.7505,  loss:0.5084,  val_accuracy:0.7580,  val_loss:0.5095,  
....................................................................................................
Epoch: 1000, accuracy:0.7502,  loss:0.5045,  val_accuracy:0.7087,  val_loss:0.5446,  
....................................................................................................
Epoch: 1100, accuracy:0.7165,  loss:0.5448,  val_accuracy:0.7652,  val_loss:0.5109,  
....................................................................................................
Epoch: 1200, accuracy:0.7386,  loss:0.5124,  val_accuracy:0.7420,  val_loss:0.5228,  
....................................................................................................
Epoch: 1300, accuracy:0.7679,  loss:0.4754,  val_accuracy:0.7696,  val_loss:0.4937,  
....................................................................................................
Epoch: 1400, accuracy:0.7451,  loss:0.4951,  val_accuracy:0.7739,  val_loss:0.4920,  
....................................................................................................
Epoch: 1500, accuracy:0.7803,  loss:0.4610,  val_accuracy:0.7913,  val_loss:0.4781,  
....................................................................................................
Epoch: 1600, accuracy:0.7857,  loss:0.4520,  val_accuracy:0.7899,  val_loss:0.4705,  
....................................................................................................
Epoch: 1700, accuracy:0.7806,  loss:0.4511,  val_accuracy:0.7768,  val_loss:0.4811,  
....................................................................................................
Epoch: 1800, accuracy:0.7313,  loss:0.5127,  val_accuracy:0.7478,  val_loss:0.5045,  
....................................................................................................
Epoch: 1900, accuracy:0.7962,  loss:0.4383,  val_accuracy:0.7913,  val_loss:0.4581,  
....................................................................................................
Fold 2:

Epoch: 0, accuracy:0.4724,  loss:0.7904,  val_accuracy:0.5000,  val_loss:0.7427,  
....................................................................................................
Epoch: 100, accuracy:0.6610,  loss:0.6081,  val_accuracy:0.6580,  val_loss:0.6265,  
....................................................................................................
Epoch: 200, accuracy:0.7052,  loss:0.5747,  val_accuracy:0.6884,  val_loss:0.6050,  
....................................................................................................
Epoch: 300, accuracy:0.7034,  loss:0.5712,  val_accuracy:0.6739,  val_loss:0.6317,  
....................................................................................................
Epoch: 400, accuracy:0.7099,  loss:0.5529,  val_accuracy:0.6986,  val_loss:0.5972,  
....................................................................................................
Epoch: 500, accuracy:0.7110,  loss:0.5522,  val_accuracy:0.7101,  val_loss:0.5723,  
....................................................................................................
Epoch: 600, accuracy:0.7273,  loss:0.5383,  val_accuracy:0.6957,  val_loss:0.5723,  
....................................................................................................
Epoch: 700, accuracy:0.7368,  loss:0.5178,  val_accuracy:0.7043,  val_loss:0.5773,  
....................................................................................................
Epoch: 800, accuracy:0.7466,  loss:0.5089,  val_accuracy:0.7188,  val_loss:0.5500,  
....................................................................................................
Epoch: 900, accuracy:0.7589,  loss:0.5018,  val_accuracy:0.7203,  val_loss:0.5399,  
....................................................................................................
Epoch: 1000, accuracy:0.7498,  loss:0.5041,  val_accuracy:0.7246,  val_loss:0.5420,  
....................................................................................................
Epoch: 1100, accuracy:0.7498,  loss:0.5002,  val_accuracy:0.7246,  val_loss:0.5344,  
....................................................................................................
Epoch: 1200, accuracy:0.7607,  loss:0.4857,  val_accuracy:0.7362,  val_loss:0.5189,  
....................................................................................................
Epoch: 1300, accuracy:0.7418,  loss:0.5204,  val_accuracy:0.7420,  val_loss:0.5158,  
....................................................................................................
Epoch: 1400, accuracy:0.7495,  loss:0.4984,  val_accuracy:0.7348,  val_loss:0.5235,  
....................................................................................................
Epoch: 1500, accuracy:0.7632,  loss:0.4771,  val_accuracy:0.7493,  val_loss:0.5087,  
....................................................................................................
Epoch: 1600, accuracy:0.7806,  loss:0.4645,  val_accuracy:0.7623,  val_loss:0.4863,  
....................................................................................................
Epoch: 1700, accuracy:0.7161,  loss:0.5561,  val_accuracy:0.7000,  val_loss:0.5782,  
....................................................................................................
Epoch: 1800, accuracy:0.7879,  loss:0.4566,  val_accuracy:0.7594,  val_loss:0.4888,  
....................................................................................................
Epoch: 1900, accuracy:0.7973,  loss:0.4456,  val_accuracy:0.7507,  val_loss:0.5055,  
....................................................................................................
Fold 3:

Epoch: 0, accuracy:0.4839,  loss:0.7824,  val_accuracy:0.5007,  val_loss:0.7118,  
....................................................................................................
Epoch: 100, accuracy:0.6549,  loss:0.6249,  val_accuracy:0.6720,  val_loss:0.6153,  
....................................................................................................
Epoch: 200, accuracy:0.6796,  loss:0.5972,  val_accuracy:0.6836,  val_loss:0.5846,  
....................................................................................................
Epoch: 300, accuracy:0.6970,  loss:0.5768,  val_accuracy:0.6923,  val_loss:0.5728,  
....................................................................................................
Epoch: 400, accuracy:0.7010,  loss:0.5695,  val_accuracy:0.7417,  val_loss:0.5383,  
....................................................................................................
Epoch: 500, accuracy:0.7068,  loss:0.5523,  val_accuracy:0.7475,  val_loss:0.5231,  
....................................................................................................
Epoch: 600, accuracy:0.7249,  loss:0.5344,  val_accuracy:0.7533,  val_loss:0.5101,  
....................................................................................................
Epoch: 700, accuracy:0.7340,  loss:0.5314,  val_accuracy:0.7388,  val_loss:0.5127,  
....................................................................................................
Epoch: 800, accuracy:0.7082,  loss:0.5589,  val_accuracy:0.7402,  val_loss:0.5101,  
....................................................................................................
Epoch: 900, accuracy:0.7470,  loss:0.5109,  val_accuracy:0.7547,  val_loss:0.4902,  
....................................................................................................
Epoch: 1000, accuracy:0.7361,  loss:0.5150,  val_accuracy:0.7446,  val_loss:0.5003,  
....................................................................................................
Epoch: 1100, accuracy:0.7550,  loss:0.4912,  val_accuracy:0.7576,  val_loss:0.4948,  
....................................................................................................
Epoch: 1200, accuracy:0.7361,  loss:0.5083,  val_accuracy:0.7649,  val_loss:0.4848,  
....................................................................................................
Epoch: 1300, accuracy:0.7488,  loss:0.4950,  val_accuracy:0.7576,  val_loss:0.4877,  
....................................................................................................
Epoch: 1400, accuracy:0.7601,  loss:0.4875,  val_accuracy:0.7808,  val_loss:0.4683,  
....................................................................................................
Epoch: 1500, accuracy:0.7760,  loss:0.4711,  val_accuracy:0.7489,  val_loss:0.5041,  
....................................................................................................
Epoch: 1600, accuracy:0.7807,  loss:0.4601,  val_accuracy:0.7547,  val_loss:0.5029,  
....................................................................................................
Epoch: 1700, accuracy:0.7499,  loss:0.5014,  val_accuracy:0.7358,  val_loss:0.5339,  
....................................................................................................
Epoch: 1800, accuracy:0.7938,  loss:0.4431,  val_accuracy:0.7808,  val_loss:0.4482,  
....................................................................................................
Epoch: 1900, accuracy:0.7901,  loss:0.4451,  val_accuracy:0.7823,  val_loss:0.4483,  
....................................................................................................
Fold 4:

Epoch: 0, accuracy:0.4947,  loss:0.7590,  val_accuracy:0.5007,  val_loss:0.7058,  
....................................................................................................
Epoch: 100, accuracy:0.6723,  loss:0.6035,  val_accuracy:0.6720,  val_loss:0.6026,  
....................................................................................................
Epoch: 200, accuracy:0.7035,  loss:0.5731,  val_accuracy:0.6996,  val_loss:0.5966,  
....................................................................................................
Epoch: 300, accuracy:0.7013,  loss:0.5673,  val_accuracy:0.7126,  val_loss:0.5696,  
....................................................................................................
Epoch: 400, accuracy:0.7064,  loss:0.5470,  val_accuracy:0.7170,  val_loss:0.5441,  
....................................................................................................
Epoch: 500, accuracy:0.7311,  loss:0.5306,  val_accuracy:0.6996,  val_loss:0.5380,  
....................................................................................................
Epoch: 600, accuracy:0.7408,  loss:0.5191,  val_accuracy:0.7344,  val_loss:0.5193,  
....................................................................................................
Epoch: 700, accuracy:0.7379,  loss:0.5206,  val_accuracy:0.7141,  val_loss:0.5490,  
....................................................................................................
Epoch: 800, accuracy:0.7608,  loss:0.4969,  val_accuracy:0.7518,  val_loss:0.5097,  
....................................................................................................
Epoch: 900, accuracy:0.7611,  loss:0.4875,  val_accuracy:0.7736,  val_loss:0.4963,  
....................................................................................................
Epoch: 1000, accuracy:0.7604,  loss:0.4895,  val_accuracy:0.7678,  val_loss:0.4930,  
....................................................................................................
Epoch: 1100, accuracy:0.7597,  loss:0.4930,  val_accuracy:0.7489,  val_loss:0.5004,  
....................................................................................................
Epoch: 1200, accuracy:0.7825,  loss:0.4678,  val_accuracy:0.7736,  val_loss:0.4779,  
....................................................................................................
Epoch: 1300, accuracy:0.7224,  loss:0.5423,  val_accuracy:0.7736,  val_loss:0.4750,  
....................................................................................................
Epoch: 1400, accuracy:0.7829,  loss:0.4602,  val_accuracy:0.7025,  val_loss:0.5634,  
....................................................................................................
Epoch: 1500, accuracy:0.7789,  loss:0.4579,  val_accuracy:0.7881,  val_loss:0.4587,  
....................................................................................................
Epoch: 1600, accuracy:0.7742,  loss:0.4548,  val_accuracy:0.7170,  val_loss:0.5777,  
....................................................................................................
Epoch: 1700, accuracy:0.7789,  loss:0.4552,  val_accuracy:0.7837,  val_loss:0.4566,  
....................................................................................................
Epoch: 1800, accuracy:0.8039,  loss:0.4251,  val_accuracy:0.7358,  val_loss:0.5266,  
....................................................................................................
Epoch: 1900, accuracy:0.7829,  loss:0.4505,  val_accuracy:0.7983,  val_loss:0.4351,  
....................................................................................................</code></pre>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-26" href="notebooks/deep_learning_cv.ipynb.html#bigloop">Source: deep_learning_cv.ipynb</a></div>
<p>You can plot the accuracy vs epochs of each fold and see how they are different for each other</p>
<div class="quarto-embed-nb-cell">
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(histories[<span class="st">'fold0'</span>].history[<span class="st">'accuracy'</span>]) <span class="op">+</span> <span class="dv">1</span>), histories[<span class="st">'fold0'</span>].history[<span class="st">'accuracy'</span>])</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(histories[<span class="st">'fold1'</span>].history[<span class="st">'accuracy'</span>]) <span class="op">+</span> <span class="dv">1</span>), histories[<span class="st">'fold1'</span>].history[<span class="st">'accuracy'</span>])</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(histories[<span class="st">'fold1'</span>].history[<span class="st">'accuracy'</span>]) <span class="op">+</span> <span class="dv">1</span>), histories[<span class="st">'fold2'</span>].history[<span class="st">'accuracy'</span>])</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(histories[<span class="st">'fold1'</span>].history[<span class="st">'accuracy'</span>]) <span class="op">+</span> <span class="dv">1</span>), histories[<span class="st">'fold3'</span>].history[<span class="st">'accuracy'</span>])</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(histories[<span class="st">'fold1'</span>].history[<span class="st">'accuracy'</span>]) <span class="op">+</span> <span class="dv">1</span>), histories[<span class="st">'fold4'</span>].history[<span class="st">'accuracy'</span>])</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="deep_learning_files/figure-html/plot-output-1.png" id="plot" class="img-fluid"></p>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-27" href="notebooks/deep_learning_cv.ipynb.html">Source: deep_learning_cv.ipynb</a></div>
</section>
<section id="plotting-the-mean-accuracy-and-standard-deviation" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="plotting-the-mean-accuracy-and-standard-deviation"><span class="header-section-number">4.3.3</span> Plotting the mean accuracy and standard deviation</h3>
<p>Lets put together all the results in a dataframe</p>
<div class="quarto-embed-nb-cell">
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>acc_total <span class="op">=</span> []</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key <span class="kw">in</span> histories.keys():</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    acc_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    acc_df[<span class="st">'val_accuracy'</span>] <span class="op">=</span> pd.DataFrame(histories[key].history[<span class="st">'val_accuracy'</span>])</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    acc_df[<span class="st">'accuracy'</span>] <span class="op">=</span> pd.DataFrame(histories[key].history[<span class="st">'accuracy'</span>])</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    acc_df[<span class="st">'type'</span>] <span class="op">=</span> key</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    acc_df[<span class="st">'epochs'</span>] <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(histories[key].history[<span class="st">'accuracy'</span>]) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>    acc_total.append(acc_df)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>df_total <span class="op">=</span> pd.concat(acc_total)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>df_total</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="dataframe" class="cell-output cell-output-display" data-execution_count="72">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">val_accuracy</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">type</th>
<th data-quarto-table-cell-role="th">epochs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.500000</td>
<td>0.500363</td>
<td>fold0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.498551</td>
<td>0.505801</td>
<td>fold0</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.518841</td>
<td>0.542422</td>
<td>fold0</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.543478</td>
<td>0.542785</td>
<td>fold0</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.620290</td>
<td>0.600435</td>
<td>fold0</td>
<td>5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1995</td>
<td>0.780842</td>
<td>0.794853</td>
<td>fold4</td>
<td>1996</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1996</td>
<td>0.801161</td>
<td>0.802102</td>
<td>fold4</td>
<td>1997</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1997</td>
<td>0.770682</td>
<td>0.810801</td>
<td>fold4</td>
<td>1998</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1998</td>
<td>0.799710</td>
<td>0.793766</td>
<td>fold4</td>
<td>1999</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1999</td>
<td>0.780842</td>
<td>0.811163</td>
<td>fold4</td>
<td>2000</td>
</tr>
</tbody>
</table>

<p>10000 rows × 4 columns</p>
</div>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-28" href="notebooks/deep_learning_cv.ipynb.html">Source: deep_learning_cv.ipynb</a></div>
<p>and plot a line with the standard deviation using <code>seaborn</code> built-in lineplot function.</p>
<div class="quarto-embed-nb-cell">
<div id="finalplot" class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">4</span>))</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df_total, x<span class="op">=</span><span class="st">"epochs"</span>, y<span class="op">=</span><span class="st">"accuracy"</span>, errorbar<span class="op">=</span>(<span class="st">'sd'</span>, <span class="dv">1</span>), ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df_total, x<span class="op">=</span><span class="st">"epochs"</span>, y<span class="op">=</span><span class="st">"val_accuracy"</span>, errorbar<span class="op">=</span>(<span class="st">'sd'</span>, <span class="dv">1</span>), ax<span class="op">=</span>ax, label<span class="op">=</span> <span class="st">'val accuracy'</span>)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="fl">0.2</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="finalplot-1" class="cell-output cell-output-display" data-execution_count="71">
<pre><code>(0.2, 1.0)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="deep_learning_files/figure-html/finalplot-output-2.png" id="finalplot-2" class="img-fluid"></p>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-29" href="notebooks/deep_learning_cv.ipynb.html#finalplot">Source: deep_learning_cv.ipynb</a></div>
<p>You can expand this even futher by split again the train set into train and validation set. You can also report the accuracy of your model as the mean plus the standard deviation.</p>
</section>
</section>
<section id="tuning-a-deep-learning-model" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="tuning-a-deep-learning-model"><span class="header-section-number">4.4</span> Tuning a deep learning model</h2>
<p>Hyperparameter tuning deep learning models is an art by itself. It will requiere you to run loads of experiements, but also it requieres a deeper understading of your data and model architecture. So, take it easy, it will take time! This example is just a basic pipeline for hyperparameter tuning that once you understand it, you can expand it according to your needs.</p>
<p>We are using keras built in tuner (needs to be installed).</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./mlpipelines.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Machine learning pipelines</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./xgboost.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">XGboost for spectroscopy</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>